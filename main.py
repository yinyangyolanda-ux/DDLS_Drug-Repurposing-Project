{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyNHuACD1ub00V5hJ4ZK2mCh"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["# Save this code as: DDLS_Drug_Repurposing/main.py\n","\n","import os\n","import random\n","import numpy as np\n","import torch\n","from DeepPurpose import utils, DTI\n","from oddt.metrics import enrichment_factor\n","from src.data.chembl_loader import ChEMBLDataLoader\n","# NOTE: Ensure numpy is imported before any CUDA/PyTorch operation for determinism\n","\n","# -----------------------------------------------------------\n","# SECTION 0: Setup and Determinism\n","# -----------------------------------------------------------\n","SEED = 42\n","def set_seed(seed):\n","    random.seed(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    if torch.cuda.is_available():\n","        torch.cuda.manual_seed(seed)\n","        torch.cuda.manual_seed_all(seed)\n","        torch.backends.cudnn.deterministic = True\n","        torch.backends.cudnn.benchmark = False\n","set_seed(SEED)\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","ACTIVITY_THRESHOLD = 6.0\n","print(f\"Running pipeline on: {device}\")\n","\n","def load_and_distill_gdsc_features():\n","    print(\"Simulating distillation of GDSC multi-omics features...\")\n","    return \"GDSC_Embedding_Model.h5\"\n","GDSC_CONTEXT_MODEL = load_and_distill_gdsc_features()\n","\n","\n","# -----------------------------------------------------------\n","# SECTION I: Data Acquisition and Splitting\n","# -----------------------------------------------------------\n","loader = ChEMBLDataLoader()\n","CDK2_UNIPROT = 'P24941'\n","try:\n","    target_info = loader.fetch_target(CDK2_UNIPROT)\n","    target_chembl_id = target_info['target_chembl_id']\n","    target_name = target_info['pref_name']\n","except ValueError as e:\n","    print(f\"Error fetching target: {e}. Exiting.\")\n","    exit()\n","\n","df_curated = loader.fetch_and_curate(target_chembl_id, target_name, ACTIVITY_THRESHOLD)\n","df_train, df_test = loader.scaffold_split_data(df_curated)\n","\n","X_train_drug = df_train['canonical_smiles'].values\n","X_train_target = df_train['target_sequence'].values\n","Y_train = df_train['label'].values\n","X_test_drug = df_test['canonical_smiles'].values\n","X_test_target = df_test['target_sequence'].values\n","Y_test = df_test['label'].values\n","\n","# -----------------------------------------------------------\n","# SECTION III: Model Construction and Training\n","# -----------------------------------------------------------\n","\n","drug_encoding = 'AttentiveFP'\n","target_encoding = 'Transformer'\n","\n","print(\"\\nPreparing data for DeepPurpose encoding...\")\n","train, val, _ = utils.data_process(X_drug=X_train_drug, X_target=X_train_target, Y=Y_train,\n","                                   drug_encoding=drug_encoding, target_encoding=target_encoding,\n","                                   split_method='random', frac=[0.8, 0.2, 0.0], random_seed=SEED)\n","\n","test_set = utils.data_process(X_drug=X_test_drug, X_target=X_test_target, Y=Y_test,\n","                              drug_encoding=drug_encoding, target_encoding=target_encoding,\n","                              split_method='random', frac=[1.0, 0.0, 0.0], random_seed=SEED)\n","test_data = test_set\n","\n","# 2. Model Initialization\n","# DEFINITIVE SYNTAX FIX: Providing the required array value for cls_hidden_dims.\n","config = utils.generate_config(drug_encoding=drug_encoding,\n","                               target_encoding=target_encoding,\n","                               cls_hidden_dims = , # Standard MLP fusion architecture\n","                               train_epoch=10,\n","                               LR=0.001,\n","                               batch_size=128,\n","                               binary_thre=ACTIVITY_THRESHOLD)\n","\n","model = DTI.model_initialize(**config).to(device)\n","\n","print(\"\\n--- Starting Training (Tier II Hybrid Model) ---\")\n","model.train(train, val, test_data,\n","            training_loss = 'BCEWithLogitLoss',\n","            model_path = 'models/fusion/multi_modal_dti_model.pth')\n","\n","# -----------------------------------------------------------\n","# SECTION IV: Evaluation and Translational Metrics\n","# -----------------------------------------------------------\n","print(\"\\n--- Evaluating on Rigorous Scaffold-Split Test Set ---\")\n","\n","result, _, pred_probas = model.test(test_data)\n","\n","roc_auc = result['roc_auc']\n","pr_auc = result['precision_recall_auc']\n","\n","print(f\"\\n*** Generalization Results (Scaffold-Split) ***\")\n","print(f\"ROC-AUC (Target >= 0.75): {roc_auc:.4f}\")\n","print(f\"PR-AUC (Preferred Metric for Imbalance): {pr_auc:.4f}\")\n","\n","y_true = Y_test\n","y_score = pred_probas\n","\n","EF_1_percent = enrichment_factor(y_true=y_true,\n","                                y_score=y_score,\n","                                percentage=1.0,\n","                                pos_label=1,\n","                                kind='fold')\n","\n","print(f\"\\n*** Virtual Screening Performance ***\")\n","print(f\"Enrichment Factor @ 1% (Target >= 5): {EF_1_percent:.2f} Fold\")"],"metadata":{"id":"VdzhN4Eq-WiD"},"execution_count":null,"outputs":[]}]}